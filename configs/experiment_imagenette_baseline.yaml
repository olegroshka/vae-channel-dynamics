# ---------- run metadata ----------
project_name: vae-dyn
run_name: sdxl_vae_imagenette_baseline
output_dir: ./results
seed: 42

# ---------- model ----------
model:
  pretrained_vae_name: stabilityai/sdxl-vae

# ---------- data ----------
data:
  dataset_name: frgfm/imagenette # Standard ImageNette dataset on Hub
  dataset_config_name: 320px
  image_column: image
  resolution: 128
  max_samples: null                        # use the full ~14 k images
  batch_size: 32
  num_workers: 4
  do_validation: true
  validation_split_name: validation
  validation_max_samples: null
  validation_batch_size: 32

# ---------- training ----------
training:
  num_train_epochs: 30
  learning_rate: 5e-5
  gradient_accumulation_steps: 1
  mixed_precision: "no"
  kl_weight: 1e-6
  max_grad_norm: 1.0
  validation_epochs: 1

# ---------- logging & saving ----------
logging:
  log_interval: 20
  report_to: wandb
saving:
  save_interval_steps: 1000
  checkpoint_dir_prefix: chkpt

# ---------- dead-neuron weight tracking ----------
dead_neuron_tracking:
  enabled: true
  track_interval: 200
  threshold: 1e-3
  target_layer_names_for_raw_weights:
    - vae.encoder.conv_in.weight
    - vae.decoder.conv_out.weight

# ---------- activation monitoring ----------
tracking:
  enabled: true
  track_interval: 20
  target_layers:
    - {name: "vae.encoder.conv_in",                       capture_point: "output", metrics: ["mean_abs_activation_per_channel"]}
    - {name: "vae.encoder.down_blocks.0.resnets.0.norm1", capture_point: "output", metrics: ["mean_abs_activation_per_channel"]}
    - {name: "vae.decoder.up_blocks.1.resnets.0.norm1",   capture_point: "output", metrics: ["mean_abs_activation_per_channel"]}

# ---------- logit-lens ----------
logit_lens:
  enabled: true
  visualization_interval: 1000
  num_channels_to_viz: 2
  num_batch_samples_to_viz: 1
  run_mini_decoder_projection: true

# ---------- classifier / intervention ----------
classification:
  enabled: false
intervention:
  enabled: false
