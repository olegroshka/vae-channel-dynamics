# configs/experiment_cifar10_test.yaml

defaults:
  - base_config

# Override specific settings for this CIFAR-10 test run
run_name: "sdxl_vae_cifar10_test_run"

# Threshold for DeadNeuronTracker (weights).
# Set higher to test if plot generates. Tune based on actual weight scales later.
threshold: 1e-3 # Was "1e-5", then "0.05". Let's try 0.01.

mean_percentage: 0.1 # For DeadNeuronTracker if dead_type uses it
dead_type: "both"    # For DeadNeuronTracker

data:
  dataset_name: "uoft-cs/cifar10"
  image_column: "img"
  resolution: 64
  max_samples: 100
  batch_size: 8
  num_workers: 0
  do_validation: true
  validation_split_name: "test"
  validation_dataset_name: "uoft-cs/cifar10"
  validation_max_samples: 50
  validation_batch_size: 8

training:
  num_train_epochs: 10
  learning_rate: "5e-5"
  gradient_accumulation_steps: 1
  mixed_precision: "no"
  kl_weight: "1e-6"
  max_grad_norm: 1.0
  validation_epochs: 1
  validation_steps: 0

logging:
  log_interval: 10
  report_to: "wandb"
saving:
  save_interval_steps: 50
  checkpoint_dir_prefix: "chkpt"

dead_neuron_tracking: # Config section for DeadNeuronTracker
  enabled: true
  track_interval: 10 # More frequent for this short dev run (e.g., every 20 steps)
  # List of specific parameter names for which to store raw weight history (for heatmaps)
  target_layer_names_for_raw_weights:
    - "vae.encoder.conv_in.weight"
    - "vae.decoder.conv_out.weight"
    - "vae.encoder.down_blocks.0.resnets.0.norm1.weight" # A GroupNorm weight
    - "vae.encoder.down_blocks.0.resnets.0.norm1.bias"   # A GroupNorm bias
    - "vae.decoder.up_blocks.0.resnets.0.norm1.weight" # Another GroupNorm weight
    - "vae.decoder.up_blocks.0.resnets.0.norm1.bias"   # Another GroupNorm bias
    - "vae.decoder.up_blocks.1.resnets.0.norm1.weight" # Another GroupNorm weight
    - "vae.decoder.up_blocks.1.resnets.0.norm1.bias"   # Another GroupNorm bias

tracking: # Config section for ActivityMonitor
  enabled: true
  track_interval: 10 # ActivityMonitor processes data every 10 steps
  target_layers:
    - name: "vae.encoder.conv_in"
      capture_point: "output"
      metrics: ["mean_abs_activation_per_channel"]
    - name: "vae.encoder.down_blocks.0.resnets.0.norm1" # GN for classifier & LogitLens
      capture_point: "output" # For classifier
      metrics: ["mean_abs_activation_per_channel", "full_activation_map"]
    - name: "vae.encoder.down_blocks.0.resnets.0.norm1" # Also capture INPUT for LogitLens
      capture_point: "input"
      metrics: ["full_activation_map"]
    - name: "vae.decoder.up_blocks.0.resnets.0.norm1"   # Another GN
      capture_point: "output"
      metrics: ["mean_abs_activation_per_channel"]
    - name: "vae.decoder.up_blocks.1.resnets.0.norm1" # GN for classifier
      capture_point: "output"
      metrics: ["mean_abs_activation_per_channel"]
    # Example for another LogitLens target (ensure this layer exists and you want its input)
    # - name: "vae.decoder.up_blocks.2.resnets.2.norm2"
    #   capture_point: "input"
    #   metrics: ["full_activation_map"]

logit_lens:
  enabled: true
  visualization_interval: 20
  target_tracked_metrics: # These MUST match keys from ActivityMonitor's output
    - "vae.encoder.down_blocks.0.resnets.0.norm1.output.mean_abs_activation_per_channel"
    - "vae.encoder.down_blocks.0.resnets.0.norm1.output.full_activation_map"
    # (layer_name + "." + capture_point + "." + metric_name)
    #- "vae.encoder.down_blocks.0.resnets.0.norm1.input.full_activation_map" # Matches tracking above
    # If you added tracking for the decoder layer above, uncomment this:
    # - "vae.decoder.up_blocks.2.resnets.2.norm2.input.full_activation_map"
  layers_to_analyze_direct: []
  num_channels_to_viz: 2
  num_batch_samples_to_viz: 1
  colormap: 'viridis'
  run_mini_decoder_projection: true
  # Add specific args for run_logit_lens_with_activations if **logit_lens_config isn't used by VAELogitLens
  # For example, if VAELogitLens expects 'layers_to_analyze', 'num_batch_samples_to_viz', etc. explicitly.
  # The current train.py passes them like this:
  # layers_to_analyze=logit_lens_config.get("layers_to_analyze_direct", logit_lens_config.get("target_tracked_metrics", [])),
  # num_batch_samples_to_viz=logit_lens_config.get("num_batch_samples_to_viz", 1),
  # projection_type=logit_lens_config.get("projection_type", "mini_decoder_single_channel")


classification:
  enabled: true
  method: "threshold_groupnorm_activity"
  threshold: 0.2
  target_metric_key: "mean_abs_activation_per_channel"
  layers_to_classify:
    - "vae.encoder.down_blocks.0.resnets.0.norm1.output"
    - "vae.decoder.up_blocks.1.resnets.0.norm1.output"

#Plotting top 10 (max 10) layers for dead neuron percentage:
#  ['decoder.conv_norm_out.bias', 'decoder.conv_norm_out.weight', 'encoder.conv_norm_out.bias', 'encoder.conv_norm_out.weight', 'decoder.mid_block.attentions.0.group_norm.bias', 'decoder.mid_block.attentions.0.group_norm.weight',
#   'encoder.down_blocks.0.resnets.1.norm2.bias', 'decoder.up_blocks.2.resnets.0.conv_shortcut.weight', 'encoder.down_blocks.0.resnets.1.norm2.weight', 'decoder.conv_out.weight']

intervention:
  enabled: true
  strategy: "gentle_nudge_groupnorm_scale"
  nudge_factor: 1.05
  max_scale_value: 1.5
  intervention_interval: 20
